import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import ember
import argparse

parser = argparse.ArgumentParser()
parser.add_argument("binaries", help="PE files to classify")
args = parser.parse_args()

import torch
import torch.nn as nn
import torch.nn.functional as F

class MalConv(nn.Module):
    def __init__(self, input_length=2000000, embedding_dim=8, window_size=500, output_dim=1):
        super(MalConv, self).__init__()
        self.embed = nn.Embedding(2381, embedding_dim)  # Assuming 2381 as the input_dim
        self.conv1 = nn.Conv1d(embedding_dim, 128, kernel_size=window_size, stride=window_size, padding=0)
        self.conv2 = nn.Conv1d(embedding_dim, 128, kernel_size=window_size, stride=window_size, padding=0)
        self.gating = nn.Sigmoid()
        self.global_max_pool = nn.AdaptiveMaxPool1d(1)
        self.fc1 = nn.Linear(128, 128)
        self.fc2 = nn.Linear(128, output_dim)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.embed(x)
        x = x.transpose(1, 2)  # Convert to (batch_size, channels, length)
        conv1 = self.conv1(x)
        conv2 = self.conv2(x)
        gated = conv1 * self.gating(conv2)  # Element-wise multiplication
        global_max_pool = self.global_max_pool(gated).squeeze(2)  # Remove the last dimension
        fc1 = F.relu(self.fc1(global_max_pool))
        fc2 = self.fc2(fc1)
        output = self.sigmoid(fc2)
        return output
    
# # Define a function to load the trained model
# def load_model(model_path):
#     model = MalConv()  # Initialize model
#     model.load_state_dict(torch.load(model_path))
#     model.eval()
#     return model

# # Define a function to preprocess the PE file
# def preprocess_PE_file(file_path, input_length):
    
#     test_file = open(file_path, 'rb').read() # read PE file
#     extract_PE = ember.PEFeatureExtractor() # initialize extractor
#     input_PE = extract_PE.feature_vector(test_file) # read feature vector
#     input_tensor = torch.tensor(input_PE)
#     byte_seq = input_tensor.byte() # get byte sequence
#     input_data = byte_seq.reshape(1, 2381) 
    
#     return input_data

# # Define a function to classify PE file using the trained model
# def classify_PE_file(file_path, model_Path, input_length):
#     # Preprocess the PE file
#     input_data = preprocess_PE_file(file_path, input_length)

#     # Run the preprocessed data through the trained model
#     model = load_model(model_Path) # load model
#     with torch.no_grad():
#         output = model(input_data)
        
#     prediction = output > 0.5
    
#     if prediction:
#         return "Malware"
#     else:
#         return "Benign"
    
# if __name__ == "__main__":
    
    
#     file_arg = args.binaries
#     model_path = 'vMalConv/model_epoch_8.pt'
#     file_b1 = '002ce0d28ec990aadbbc89df457189de37d8adaadc9c084b78eb7be9a9820c81.exe'
#     file_b2 = '02431aa60089b968bc59acc69796ed9418546894752d0c9766fbe3aae0a85031.exe'
#     label = 0
#     input_length = 2000000

#     # Classify the PE file
#     prediction = classify_PE_file(file_b1, model_path, input_length)

#     # Print the prediction
#     print("Prediction:", prediction)
    
    
import os
import torch

def model_fn(model_dir):
    """
    Load the model for inference
    """

    # Define the path to the model checkpoint
    checkpoint_path = os.path.join(model_dir, 'model_epoch_15.pt')  # Assuming you want to load the last checkpoint

    # Initialize the model
    model = MalConv()

    # Load the model checkpoint
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
    model.load_state_dict(checkpoint['model_state_dict'])

    # Set the model to evaluation mode
    model.eval()

    return model



    return model
def predict_fn(input_data, model):
    """
    Apply model to the incoming request
    """

#     input_data = preprocess_PE_file(file_path, input_length)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    # Run the preprocessed data through the trained model
#     model = load_model(model_Path) # load model
    with torch.no_grad():
        output = model(input_data)
        
    prediction = output > 0.5
    
    if prediction:
        return "Malware"
    else:
        return "Benign"

def input_fn(request_body, request_content_type):
    """
    Deserialize and prepare the prediction input
    """

    if request_content_type == 'application/python-pickle':
        return torch.load(BytesIO(request_body))
    else:
        test_file = open(request_body, 'rb').read() # read PE file
        extract_PE = ember.PEFeatureExtractor() # initialize extractor
        input_PE = extract_PE.feature_vector(test_file) # read feature vector
        input_tensor = torch.tensor(input_PE)
        byte_seq = input_tensor.byte() # get byte sequence
        input_data = byte_seq.reshape(1, 2381) 
    
    return input_data

#     return request

def output_fn(prediction, response_content_type):
    """
    Serialize and prepare the prediction output
    """

    if response_content_type == "application/json":
        response = str(prediction)
    else:
        response = str(prediction)

    return response